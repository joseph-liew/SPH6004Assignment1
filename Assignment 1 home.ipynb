{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5238219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>mbp_min</th>\n",
       "      <th>mbp_max</th>\n",
       "      <th>mbp_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>bilirubin_indirect_min</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>sofa_respiration</th>\n",
       "      <th>sofa_coagulation</th>\n",
       "      <th>sofa_liver</th>\n",
       "      <th>sofa_cardiovascular</th>\n",
       "      <th>sofa_cns</th>\n",
       "      <th>sofa_renal</th>\n",
       "      <th>charlson_comorbidity_index</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>54.550390</td>\n",
       "      <td>93.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.733333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3459.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>86.324653</td>\n",
       "      <td>50.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>54.333333</td>\n",
       "      <td>61.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>71.695652</td>\n",
       "      <td>95.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>40.270146</td>\n",
       "      <td>70.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>83.434783</td>\n",
       "      <td>66.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>76.695652</td>\n",
       "      <td>94.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>73.383547</td>\n",
       "      <td>68.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>83.880000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>84.694444</td>\n",
       "      <td>83.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>70.724748</td>\n",
       "      <td>77.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>85.771429</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>62.657143</td>\n",
       "      <td>52.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender        age  heart_rate_min  heart_rate_max  heart_rate_mean  mbp_min  \\\n",
       "0      M  54.550390            93.0           115.0       103.500000     57.0   \n",
       "1      M  86.324653            50.0            61.0        54.333333     61.0   \n",
       "2      M  40.270146            70.0           105.0        83.434783     66.0   \n",
       "3      M  73.383547            68.0            98.0        83.880000     74.0   \n",
       "4      M  70.724748            77.0            95.0        85.771429     30.0   \n",
       "\n",
       "   mbp_max   mbp_mean  sbp_min  sbp_max  ...  bilirubin_indirect_min  \\\n",
       "0    100.0  82.733333     87.0    163.0  ...                     NaN   \n",
       "1     93.0  71.695652     95.0    141.0  ...                     NaN   \n",
       "2     92.0  76.695652     94.0    129.0  ...                     NaN   \n",
       "3    101.0  84.694444     83.0    148.0  ...                     NaN   \n",
       "4     90.0  62.657143     52.0    129.0  ...                     NaN   \n",
       "\n",
       "   urineoutput  sofa_respiration  sofa_coagulation  sofa_liver  \\\n",
       "0       3459.0               2.0               0.0         NaN   \n",
       "1       2020.0               NaN               1.0         NaN   \n",
       "2       3050.0               NaN               1.0         0.0   \n",
       "3       1592.0               NaN               0.0         NaN   \n",
       "4        339.0               2.0               0.0         0.0   \n",
       "\n",
       "   sofa_cardiovascular  sofa_cns  sofa_renal  charlson_comorbidity_index  \\\n",
       "0                  1.0       0.0         1.0                           3   \n",
       "1                  1.0       1.0         1.0                           8   \n",
       "2                  1.0       1.0         0.0                           4   \n",
       "3                  0.0       0.0         1.0                           6   \n",
       "4                  4.0       1.0         3.0                          10   \n",
       "\n",
       "   outcome  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e20d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>heart_rate_min</th>\n",
       "      <th>heart_rate_max</th>\n",
       "      <th>heart_rate_mean</th>\n",
       "      <th>mbp_min</th>\n",
       "      <th>mbp_max</th>\n",
       "      <th>mbp_mean</th>\n",
       "      <th>sbp_min</th>\n",
       "      <th>sbp_max</th>\n",
       "      <th>...</th>\n",
       "      <th>bilirubin_indirect_min</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>sofa_respiration</th>\n",
       "      <th>sofa_coagulation</th>\n",
       "      <th>sofa_liver</th>\n",
       "      <th>sofa_cardiovascular</th>\n",
       "      <th>sofa_cns</th>\n",
       "      <th>sofa_renal</th>\n",
       "      <th>charlson_comorbidity_index</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36484</th>\n",
       "      <td>F</td>\n",
       "      <td>84.952721</td>\n",
       "      <td>59.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>68.538462</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>74.346154</td>\n",
       "      <td>109.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>697.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36485</th>\n",
       "      <td>F</td>\n",
       "      <td>30.583263</td>\n",
       "      <td>59.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>79.954545</td>\n",
       "      <td>67.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>77.820000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36486</th>\n",
       "      <td>F</td>\n",
       "      <td>60.095765</td>\n",
       "      <td>71.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>82.625000</td>\n",
       "      <td>51.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>61.772727</td>\n",
       "      <td>90.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36487</th>\n",
       "      <td>M</td>\n",
       "      <td>78.847051</td>\n",
       "      <td>63.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>72.836735</td>\n",
       "      <td>113.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36488</th>\n",
       "      <td>M</td>\n",
       "      <td>32.783457</td>\n",
       "      <td>86.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>99.916667</td>\n",
       "      <td>97.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender        age  heart_rate_min  heart_rate_max  heart_rate_mean  \\\n",
       "36484      F  84.952721            59.0            80.0        68.538462   \n",
       "36485      F  30.583263            59.0           104.0        79.954545   \n",
       "36486      F  60.095765            71.0            94.0        82.625000   \n",
       "36487      M  78.847051            63.0            86.0        72.836735   \n",
       "36488      M  32.783457            86.0           103.0        94.000000   \n",
       "\n",
       "       mbp_min  mbp_max    mbp_mean  sbp_min  sbp_max  ...  \\\n",
       "36484      2.0     95.0   74.346154    109.0    152.0  ...   \n",
       "36485     67.0     91.0   77.820000     94.0    140.0  ...   \n",
       "36486     51.0     92.0   61.772727     90.0    120.0  ...   \n",
       "36487    113.0    121.0  117.000000    148.0    219.0  ...   \n",
       "36488     83.0    118.0   99.916667     97.0    176.0  ...   \n",
       "\n",
       "       bilirubin_indirect_min  urineoutput  sofa_respiration  \\\n",
       "36484                     NaN        697.0               NaN   \n",
       "36485                     NaN       2000.0               NaN   \n",
       "36486                     NaN       3500.0               NaN   \n",
       "36487                     NaN       1900.0               NaN   \n",
       "36488                     NaN          NaN               NaN   \n",
       "\n",
       "       sofa_coagulation  sofa_liver  sofa_cardiovascular  sofa_cns  \\\n",
       "36484               0.0         0.0                  1.0       4.0   \n",
       "36485               0.0         NaN                  1.0       1.0   \n",
       "36486               0.0         NaN                  1.0       0.0   \n",
       "36487               0.0         NaN                  0.0       1.0   \n",
       "36488               0.0         0.0                  0.0       1.0   \n",
       "\n",
       "       sofa_renal  charlson_comorbidity_index  outcome  \n",
       "36484         1.0                          10    False  \n",
       "36485         0.0                           0    False  \n",
       "36486         0.0                           3    False  \n",
       "36487         0.0                           5    False  \n",
       "36488         4.0                           5    False  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dfb067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36489"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f19c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         object\n",
       "age                           float64\n",
       "heart_rate_min                float64\n",
       "heart_rate_max                float64\n",
       "heart_rate_mean               float64\n",
       "mbp_min                       float64\n",
       "mbp_max                       float64\n",
       "mbp_mean                      float64\n",
       "sbp_min                       float64\n",
       "sbp_max                       float64\n",
       "sbp_mean                      float64\n",
       "dbp_min                       float64\n",
       "dbp_max                       float64\n",
       "dbp_mean                      float64\n",
       "temperature_min               float64\n",
       "temperature_max               float64\n",
       "temperature_mean              float64\n",
       "lactate_min                   float64\n",
       "lactate_max                   float64\n",
       "ph_min                        float64\n",
       "ph_max                        float64\n",
       "chloride_min                  float64\n",
       "chloride_max                  float64\n",
       "calcium_min                   float64\n",
       "calcium_max                   float64\n",
       "sodium_min                    float64\n",
       "sodium_max                    float64\n",
       "glucose_min                   float64\n",
       "glucose_max                   float64\n",
       "wbc_min                       float64\n",
       "wbc_max                       float64\n",
       "creatinine_min                float64\n",
       "creatinine_max                float64\n",
       "hemoglobin_min                float64\n",
       "hemoglobin_max                float64\n",
       "total_protein_max             float64\n",
       "total_protein_min             float64\n",
       "pt_min                        float64\n",
       "pt_max                        float64\n",
       "alt_max                       float64\n",
       "alt_min                       float64\n",
       "alp_max                       float64\n",
       "alp_min                       float64\n",
       "ast_min                       float64\n",
       "ast_max                       float64\n",
       "bilirubin_total_max           float64\n",
       "bilirubin_total_min           float64\n",
       "bilirubin_direct_max          float64\n",
       "bilirubin_direct_min          float64\n",
       "bilirubin_indirect_max        float64\n",
       "bilirubin_indirect_min        float64\n",
       "urineoutput                   float64\n",
       "sofa_respiration              float64\n",
       "sofa_coagulation              float64\n",
       "sofa_liver                    float64\n",
       "sofa_cardiovascular           float64\n",
       "sofa_cns                      float64\n",
       "sofa_renal                    float64\n",
       "charlson_comorbidity_index      int64\n",
       "outcome                          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2ddf5",
   "metadata": {},
   "source": [
    "**Descriptive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f5a2288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   age  heart_rate_min  heart_rate_max  heart_rate_mean  \\\n",
      "count     36489.000000    36417.000000    36417.000000     36417.000000   \n",
      "mean         65.907162       70.935003      103.109572        84.855578   \n",
      "std          16.797498       15.064109       20.682937        15.977454   \n",
      "min          18.002527        9.000000       36.000000        28.500000   \n",
      "25%          55.549252       60.000000       88.000000        73.321429   \n",
      "50%          67.439033       70.000000      101.000000        83.500000   \n",
      "75%          78.729524       80.000000      115.000000        95.250000   \n",
      "max         102.865603      163.000000      295.000000       174.740741   \n",
      "missing%      0.000000        0.197320        0.197320         0.197320   \n",
      "\n",
      "               mbp_min       mbp_max      mbp_mean       sbp_min  \\\n",
      "count     36401.000000  36401.000000  36401.000000  36343.000000   \n",
      "mean         60.429777    105.484634     79.255689     94.449898   \n",
      "std          13.347348     23.346984     11.758700     16.705217   \n",
      "min           0.830000     51.000000     42.513889      2.000000   \n",
      "25%          53.000000     91.000000     70.896552     83.500000   \n",
      "50%          60.000000    102.000000     77.851852     93.000000   \n",
      "75%          68.000000    115.000000     86.382353    104.000000   \n",
      "max         133.000000    299.000000    151.529412    184.000000   \n",
      "missing%      0.241169      0.241169      0.241169      0.400121   \n",
      "\n",
      "               sbp_max      sbp_mean       dbp_min       dbp_max  \\\n",
      "count     36343.000000  36343.000000  36341.000000  36341.000000   \n",
      "mean        147.691412    119.757827     47.379860     90.387455   \n",
      "std          22.855348     17.220898     11.853837     20.183779   \n",
      "min          49.000000     40.000000      1.000000     29.000000   \n",
      "25%         132.000000    107.096464     40.000000     76.000000   \n",
      "50%         146.000000    117.678571     47.000000     88.000000   \n",
      "75%         161.000000    130.649616     54.000000    101.000000   \n",
      "max         352.000000    206.388889    113.000000    273.000000   \n",
      "missing%      0.400121      0.400121      0.405602      0.405602   \n",
      "\n",
      "              dbp_mean  temperature_min  temperature_max  temperature_mean  \\\n",
      "count     36341.000000     36126.000000     36126.000000      36126.000000   \n",
      "mean         64.540082        36.348090        37.296027         36.813596   \n",
      "std          11.661638         0.548462         0.622069          0.416853   \n",
      "min          29.000000        22.000000        33.400000         33.191304   \n",
      "25%          56.344828        36.170000        36.940000         36.601429   \n",
      "50%          63.304348        36.440000        37.170000         36.792857   \n",
      "75%          71.575758        36.670000        37.560000         37.010000   \n",
      "max         130.388889        38.560000        42.000000         39.517692   \n",
      "missing%      0.405602         0.994820         0.994820          0.994820   \n",
      "\n",
      "           lactate_min   lactate_max        ph_min        ph_max  \\\n",
      "count     15930.000000  15930.000000  18860.000000  18860.000000   \n",
      "mean          1.640498      2.360345      7.345907      7.406615   \n",
      "std           1.031029      1.704819      0.089457      0.070243   \n",
      "min           0.000000      0.200000      6.700000      6.810000   \n",
      "25%           1.000000      1.300000      7.300000      7.360000   \n",
      "50%           1.400000      1.900000      7.350000      7.410000   \n",
      "75%           1.900000      2.800000      7.410000      7.450000   \n",
      "max          16.800000     29.000000      7.630000      7.830000   \n",
      "missing%     56.343007     56.343007     48.313190     48.313190   \n",
      "\n",
      "          chloride_min  chloride_max  calcium_min  calcium_max   sodium_min  \\\n",
      "count      6129.000000   6129.000000  9289.000000  9289.000000  6554.000000   \n",
      "mean        103.243172    105.369457     1.085834     1.169765   134.799735   \n",
      "std           6.014638      6.219704     0.097465     0.127002     5.928459   \n",
      "min           3.400000      3.400000     0.400000     0.610000     1.360000   \n",
      "25%         101.000000    103.000000     1.040000     1.090000   133.000000   \n",
      "50%         104.000000    106.000000     1.090000     1.160000   135.000000   \n",
      "75%         106.000000    109.000000     1.140000     1.230000   137.000000   \n",
      "max         139.000000    141.000000     2.090000     2.870000   186.000000   \n",
      "missing%     83.203157     83.203157    74.543013    74.543013    82.038423   \n",
      "\n",
      "           sodium_max   glucose_min   glucose_max       wbc_min       wbc_max  \\\n",
      "count     6554.000000  36191.000000  36191.000000  36235.000000  36235.000000   \n",
      "mean       136.628792    117.663729    167.322815     10.181060     13.145738   \n",
      "std          5.776729     39.923837    113.182968      7.792171     11.082715   \n",
      "min          5.100000      7.000000      7.000000      0.100000      0.100000   \n",
      "25%        135.000000     93.000000    113.000000      6.600000      8.300000   \n",
      "50%        137.000000    109.000000    137.000000      9.000000     11.400000   \n",
      "75%        139.000000    132.000000    178.000000     12.200000     15.700000   \n",
      "max        186.000000    575.000000   2440.000000    300.400000    407.200000   \n",
      "missing%    82.038423      0.816684      0.816684      0.696100      0.696100   \n",
      "\n",
      "          creatinine_min  creatinine_max  hemoglobin_min  hemoglobin_max  \\\n",
      "count       36291.000000    36291.000000    36232.000000    36232.000000   \n",
      "mean            1.330352        1.591678       10.293279       11.393038   \n",
      "std             1.466693        1.847420        2.280191        2.172428   \n",
      "min             0.100000        0.100000        2.200000        3.700000   \n",
      "25%             0.700000        0.800000        8.600000        9.800000   \n",
      "50%             0.900000        1.000000       10.300000       11.300000   \n",
      "75%             1.300000        1.600000       11.900000       12.900000   \n",
      "max            31.800000       43.000000       19.300000       21.700000   \n",
      "missing%        0.542629        0.542629        0.704322        0.704322   \n",
      "\n",
      "          total_protein_max  total_protein_min        pt_min        pt_max  \\\n",
      "count            974.000000         974.000000  32345.000000  32345.000000   \n",
      "mean               6.041376           6.017248     14.944678     17.063756   \n",
      "std                1.070641           1.038513      6.630633     11.251566   \n",
      "min                2.000000           2.000000      8.000000      8.000000   \n",
      "25%                5.400000           5.400000     11.900000     12.300000   \n",
      "50%                6.100000           6.000000     13.100000     13.900000   \n",
      "75%                6.700000           6.600000     15.100000     16.800000   \n",
      "max               16.400000          16.400000    140.300000    154.600000   \n",
      "missing%          97.330702          97.330702     11.356847     11.356847   \n",
      "\n",
      "               alt_max       alt_min       alp_max       alp_min  \\\n",
      "count     18663.000000  18663.000000  18580.000000  18580.000000   \n",
      "mean        122.738279     83.877431    124.666954    115.245748   \n",
      "std         790.533967    395.349826    134.923888    119.240334   \n",
      "min           1.000000      1.000000      7.000000      7.000000   \n",
      "25%          15.000000     15.000000     65.000000     62.000000   \n",
      "50%          25.000000     23.000000     88.000000     83.000000   \n",
      "75%          50.000000     45.000000    131.000000    122.000000   \n",
      "max       61854.000000  11680.000000   3358.000000   3149.000000   \n",
      "missing%     48.853079     48.853079     49.080545     49.080545   \n",
      "\n",
      "               ast_min       ast_max  bilirubin_total_max  \\\n",
      "count     18776.000000  18776.000000         18590.000000   \n",
      "mean        101.127333    168.799585             1.705939   \n",
      "std         460.282124    947.025745             4.099623   \n",
      "min           2.000000      2.000000             0.100000   \n",
      "25%          20.000000     22.000000             0.400000   \n",
      "50%          31.000000     35.000000             0.600000   \n",
      "75%          60.000000     71.250000             1.300000   \n",
      "max       18970.000000  28580.000000            78.000000   \n",
      "missing%     48.543397     48.543397            49.053139   \n",
      "\n",
      "          bilirubin_total_min  bilirubin_direct_max  bilirubin_direct_min  \\\n",
      "count            18590.000000           1605.000000           1605.000000   \n",
      "mean                 1.495632              3.393146              3.213832   \n",
      "std                  3.711757              5.299470              5.110260   \n",
      "min                  0.100000              0.100000              0.100000   \n",
      "25%                  0.400000              0.600000              0.500000   \n",
      "50%                  0.600000              1.600000              1.500000   \n",
      "75%                  1.100000              3.800000              3.600000   \n",
      "max                 67.800000             63.700000             63.700000   \n",
      "missing%            49.053139             95.601414             95.601414   \n",
      "\n",
      "          bilirubin_indirect_max  bilirubin_indirect_min   urineoutput  \\\n",
      "count                1544.000000             1544.000000  35073.000000   \n",
      "mean                    1.855894                1.742163   1914.991284   \n",
      "std                     2.293747                2.219434   1266.887914   \n",
      "min                     0.100000                0.100000 -14850.000000   \n",
      "25%                     0.500000                0.500000   1050.000000   \n",
      "50%                     1.000000                1.000000   1667.000000   \n",
      "75%                     2.200000                2.000000   2500.000000   \n",
      "max                    21.200000               21.200000  31016.000000   \n",
      "missing%               95.768588               95.768588      3.880622   \n",
      "\n",
      "          sofa_respiration  sofa_coagulation    sofa_liver  \\\n",
      "count          7587.000000      36235.000000  18590.000000   \n",
      "mean              1.723738          0.481109      0.514094   \n",
      "std               0.588464          0.825034      0.963752   \n",
      "min               0.000000          0.000000      0.000000   \n",
      "25%               2.000000          0.000000      0.000000   \n",
      "50%               2.000000          0.000000      0.000000   \n",
      "75%               2.000000          1.000000      1.000000   \n",
      "max               2.000000          4.000000      4.000000   \n",
      "missing%         79.207432          0.696100     49.053139   \n",
      "\n",
      "          sofa_cardiovascular      sofa_cns    sofa_renal  \\\n",
      "count            36402.000000  36468.000000  36467.000000   \n",
      "mean                 1.060381      0.915433      0.826501   \n",
      "std                  0.972511      1.050761      1.201510   \n",
      "min                  0.000000      0.000000      0.000000   \n",
      "25%                  1.000000      0.000000      0.000000   \n",
      "50%                  1.000000      1.000000      0.000000   \n",
      "75%                  1.000000      1.000000      1.000000   \n",
      "max                  4.000000      4.000000      4.000000   \n",
      "missing%             0.238428      0.057552      0.060292   \n",
      "\n",
      "          charlson_comorbidity_index  gender  outcome  \n",
      "count                   36489.000000     NaN      NaN  \n",
      "mean                        5.798104     NaN      NaN  \n",
      "std                         3.014789     NaN      NaN  \n",
      "min                         0.000000     NaN      NaN  \n",
      "25%                         4.000000     NaN      NaN  \n",
      "50%                         6.000000     NaN      NaN  \n",
      "75%                         8.000000     NaN      NaN  \n",
      "max                        20.000000     NaN      NaN  \n",
      "missing%                    0.000000     0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "base_describe = df.describe()\n",
    "\n",
    "df_length = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "missing_percent = pd.DataFrame((missing_count / df_length) * 100).T\n",
    "missing_percent = missing_percent.rename(index = lambda i: \"missing%\")\n",
    "missing_describe = pd.concat([base_describe, missing_percent], ignore_index=False)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(missing_describe)\n",
    "\n",
    "#arr = np.loadtxt('Assignment_1_data_working.csv',delimiter=',')\n",
    "#sp.stats.describe(arr[:, :58])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92d8a5",
   "metadata": {},
   "source": [
    "**Gender and Outcome counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3b24ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender_count\n",
      "   gender\n",
      "M   19880\n",
      "F   16609\n",
      "\n",
      "\n",
      "Gender_percent\n",
      "M    54.482173\n",
      "F    45.517827\n",
      "Name: gender, dtype: float64\n",
      "\n",
      "\n",
      "Outcome_count\n",
      "       outcome\n",
      "False    35160\n",
      "True      1329\n",
      "\n",
      "\n",
      "Outcome_percent\n",
      "False    96.357806\n",
      "True      3.642194\n",
      "Name: outcome, dtype: float64\n",
      "\n",
      "\n",
      "Gender_outcome_count\n",
      "gender  outcome\n",
      "F       False      16079\n",
      "        True         530\n",
      "M       False      19081\n",
      "        True         799\n",
      "Name: outcome, dtype: int64\n",
      "\n",
      "\n",
      "Female_outcome_percent\n",
      "outcome\n",
      "False    96.808959\n",
      "True      3.191041\n",
      "Name: outcome, dtype: float64\n",
      "\n",
      "\n",
      "Male_outcome_percent\n",
      "outcome\n",
      "False    95.980885\n",
      "True      4.019115\n",
      "Name: outcome, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "base_describe = df.describe()\n",
    "\n",
    "print('Gender_count')\n",
    "gender_count = pd.DataFrame(df['gender'].value_counts())\n",
    "print(gender_count)\n",
    "print('\\n')\n",
    "\n",
    "print('Gender_percent')\n",
    "gender_percent = gender_count['gender']* 100/len(df)\n",
    "print(gender_percent)\n",
    "print('\\n')\n",
    "\n",
    "print('Outcome_count')\n",
    "outcome_count = pd.DataFrame(df['outcome'].value_counts())\n",
    "print(outcome_count)\n",
    "print('\\n')\n",
    "\n",
    "print('Outcome_percent')\n",
    "outcome_percent = outcome_count['outcome']* 100/len(df)\n",
    "print(outcome_percent)\n",
    "print('\\n')\n",
    "\n",
    "print('Gender_outcome_count')\n",
    "gender_outcome = df[['gender','outcome']]\n",
    "gender_outcome = gender_outcome.groupby('gender')['outcome'].value_counts()\n",
    "print(gender_outcome)\n",
    "print('\\n')\n",
    "\n",
    "print('Female_outcome_percent')\n",
    "female_outcome_percent = gender_outcome['F']*100/gender_outcome['F'].sum()\n",
    "print(female_outcome_percent)\n",
    "print('\\n')\n",
    "\n",
    "print('Male_outcome_percent')\n",
    "male_outcome_percent = gender_outcome['M']*100/gender_outcome['M'].sum()\n",
    "print(male_outcome_percent)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c76d6",
   "metadata": {},
   "source": [
    "**Both genders Missing >40%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d16b5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           lactate_min   lactate_max        ph_min        ph_max  \\\n",
      "count     15930.000000  15930.000000  18860.000000  18860.000000   \n",
      "mean          1.640498      2.360345      7.345907      7.406615   \n",
      "std           1.031029      1.704819      0.089457      0.070243   \n",
      "min           0.000000      0.200000      6.700000      6.810000   \n",
      "25%           1.000000      1.300000      7.300000      7.360000   \n",
      "50%           1.400000      1.900000      7.350000      7.410000   \n",
      "75%           1.900000      2.800000      7.410000      7.450000   \n",
      "max          16.800000     29.000000      7.630000      7.830000   \n",
      "missing%     56.343007     56.343007     48.313190     48.313190   \n",
      "\n",
      "          chloride_min  chloride_max  calcium_min  calcium_max   sodium_min  \\\n",
      "count      6129.000000   6129.000000  9289.000000  9289.000000  6554.000000   \n",
      "mean        103.243172    105.369457     1.085834     1.169765   134.799735   \n",
      "std           6.014638      6.219704     0.097465     0.127002     5.928459   \n",
      "min           3.400000      3.400000     0.400000     0.610000     1.360000   \n",
      "25%         101.000000    103.000000     1.040000     1.090000   133.000000   \n",
      "50%         104.000000    106.000000     1.090000     1.160000   135.000000   \n",
      "75%         106.000000    109.000000     1.140000     1.230000   137.000000   \n",
      "max         139.000000    141.000000     2.090000     2.870000   186.000000   \n",
      "missing%     83.203157     83.203157    74.543013    74.543013    82.038423   \n",
      "\n",
      "           sodium_max  total_protein_max  total_protein_min       alt_max  \\\n",
      "count     6554.000000         974.000000         974.000000  18663.000000   \n",
      "mean       136.628792           6.041376           6.017248    122.738279   \n",
      "std          5.776729           1.070641           1.038513    790.533967   \n",
      "min          5.100000           2.000000           2.000000      1.000000   \n",
      "25%        135.000000           5.400000           5.400000     15.000000   \n",
      "50%        137.000000           6.100000           6.000000     25.000000   \n",
      "75%        139.000000           6.700000           6.600000     50.000000   \n",
      "max        186.000000          16.400000          16.400000  61854.000000   \n",
      "missing%    82.038423          97.330702          97.330702     48.853079   \n",
      "\n",
      "               alt_min       alp_max       alp_min       ast_min  \\\n",
      "count     18663.000000  18580.000000  18580.000000  18776.000000   \n",
      "mean         83.877431    124.666954    115.245748    101.127333   \n",
      "std         395.349826    134.923888    119.240334    460.282124   \n",
      "min           1.000000      7.000000      7.000000      2.000000   \n",
      "25%          15.000000     65.000000     62.000000     20.000000   \n",
      "50%          23.000000     88.000000     83.000000     31.000000   \n",
      "75%          45.000000    131.000000    122.000000     60.000000   \n",
      "max       11680.000000   3358.000000   3149.000000  18970.000000   \n",
      "missing%     48.853079     49.080545     49.080545     48.543397   \n",
      "\n",
      "               ast_max  bilirubin_total_max  bilirubin_total_min  \\\n",
      "count     18776.000000         18590.000000         18590.000000   \n",
      "mean        168.799585             1.705939             1.495632   \n",
      "std         947.025745             4.099623             3.711757   \n",
      "min           2.000000             0.100000             0.100000   \n",
      "25%          22.000000             0.400000             0.400000   \n",
      "50%          35.000000             0.600000             0.600000   \n",
      "75%          71.250000             1.300000             1.100000   \n",
      "max       28580.000000            78.000000            67.800000   \n",
      "missing%     48.543397            49.053139            49.053139   \n",
      "\n",
      "          bilirubin_direct_max  bilirubin_direct_min  bilirubin_indirect_max  \\\n",
      "count              1605.000000           1605.000000             1544.000000   \n",
      "mean                  3.393146              3.213832                1.855894   \n",
      "std                   5.299470              5.110260                2.293747   \n",
      "min                   0.100000              0.100000                0.100000   \n",
      "25%                   0.600000              0.500000                0.500000   \n",
      "50%                   1.600000              1.500000                1.000000   \n",
      "75%                   3.800000              3.600000                2.200000   \n",
      "max                  63.700000             63.700000               21.200000   \n",
      "missing%             95.601414             95.601414               95.768588   \n",
      "\n",
      "          bilirubin_indirect_min  sofa_respiration    sofa_liver  \n",
      "count                1544.000000       7587.000000  18590.000000  \n",
      "mean                    1.742163          1.723738      0.514094  \n",
      "std                     2.219434          0.588464      0.963752  \n",
      "min                     0.100000          0.000000      0.000000  \n",
      "25%                     0.500000          2.000000      0.000000  \n",
      "50%                     1.000000          2.000000      0.000000  \n",
      "75%                     2.000000          2.000000      1.000000  \n",
      "max                    21.200000          2.000000      4.000000  \n",
      "missing%               95.768588         79.207432     49.053139  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "base_describe = df.describe()\n",
    "\n",
    "df_length = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "missing_percent = pd.DataFrame((missing_count / df_length) * 100).T\n",
    "missing_percent = missing_percent.rename(index = lambda i: \"missing%\")\n",
    "missing_describe = pd.concat([base_describe, missing_percent], ignore_index=False)\n",
    "\n",
    "missing_more_40p = missing_describe.T\n",
    "missing_more_40p = missing_more_40p[missing_more_40p[\"missing%\"] > 40].T\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(missing_more_40p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662a7c69",
   "metadata": {},
   "source": [
    "**Both genders Missing <=40%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c0de981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   age  heart_rate_min  heart_rate_max  heart_rate_mean  \\\n",
      "count     36489.000000    36417.000000    36417.000000     36417.000000   \n",
      "mean         65.907162       70.935003      103.109572        84.855578   \n",
      "std          16.797498       15.064109       20.682937        15.977454   \n",
      "min          18.002527        9.000000       36.000000        28.500000   \n",
      "25%          55.549252       60.000000       88.000000        73.321429   \n",
      "50%          67.439033       70.000000      101.000000        83.500000   \n",
      "75%          78.729524       80.000000      115.000000        95.250000   \n",
      "max         102.865603      163.000000      295.000000       174.740741   \n",
      "missing%      0.000000        0.197320        0.197320         0.197320   \n",
      "\n",
      "               mbp_min       mbp_max      mbp_mean       sbp_min  \\\n",
      "count     36401.000000  36401.000000  36401.000000  36343.000000   \n",
      "mean         60.429777    105.484634     79.255689     94.449898   \n",
      "std          13.347348     23.346984     11.758700     16.705217   \n",
      "min           0.830000     51.000000     42.513889      2.000000   \n",
      "25%          53.000000     91.000000     70.896552     83.500000   \n",
      "50%          60.000000    102.000000     77.851852     93.000000   \n",
      "75%          68.000000    115.000000     86.382353    104.000000   \n",
      "max         133.000000    299.000000    151.529412    184.000000   \n",
      "missing%      0.241169      0.241169      0.241169      0.400121   \n",
      "\n",
      "               sbp_max      sbp_mean       dbp_min       dbp_max  \\\n",
      "count     36343.000000  36343.000000  36341.000000  36341.000000   \n",
      "mean        147.691412    119.757827     47.379860     90.387455   \n",
      "std          22.855348     17.220898     11.853837     20.183779   \n",
      "min          49.000000     40.000000      1.000000     29.000000   \n",
      "25%         132.000000    107.096464     40.000000     76.000000   \n",
      "50%         146.000000    117.678571     47.000000     88.000000   \n",
      "75%         161.000000    130.649616     54.000000    101.000000   \n",
      "max         352.000000    206.388889    113.000000    273.000000   \n",
      "missing%      0.400121      0.400121      0.405602      0.405602   \n",
      "\n",
      "              dbp_mean  temperature_min  temperature_max  temperature_mean  \\\n",
      "count     36341.000000     36126.000000     36126.000000      36126.000000   \n",
      "mean         64.540082        36.348090        37.296027         36.813596   \n",
      "std          11.661638         0.548462         0.622069          0.416853   \n",
      "min          29.000000        22.000000        33.400000         33.191304   \n",
      "25%          56.344828        36.170000        36.940000         36.601429   \n",
      "50%          63.304348        36.440000        37.170000         36.792857   \n",
      "75%          71.575758        36.670000        37.560000         37.010000   \n",
      "max         130.388889        38.560000        42.000000         39.517692   \n",
      "missing%      0.405602         0.994820         0.994820          0.994820   \n",
      "\n",
      "           glucose_min   glucose_max       wbc_min       wbc_max  \\\n",
      "count     36191.000000  36191.000000  36235.000000  36235.000000   \n",
      "mean        117.663729    167.322815     10.181060     13.145738   \n",
      "std          39.923837    113.182968      7.792171     11.082715   \n",
      "min           7.000000      7.000000      0.100000      0.100000   \n",
      "25%          93.000000    113.000000      6.600000      8.300000   \n",
      "50%         109.000000    137.000000      9.000000     11.400000   \n",
      "75%         132.000000    178.000000     12.200000     15.700000   \n",
      "max         575.000000   2440.000000    300.400000    407.200000   \n",
      "missing%      0.816684      0.816684      0.696100      0.696100   \n",
      "\n",
      "          creatinine_min  creatinine_max  hemoglobin_min  hemoglobin_max  \\\n",
      "count       36291.000000    36291.000000    36232.000000    36232.000000   \n",
      "mean            1.330352        1.591678       10.293279       11.393038   \n",
      "std             1.466693        1.847420        2.280191        2.172428   \n",
      "min             0.100000        0.100000        2.200000        3.700000   \n",
      "25%             0.700000        0.800000        8.600000        9.800000   \n",
      "50%             0.900000        1.000000       10.300000       11.300000   \n",
      "75%             1.300000        1.600000       11.900000       12.900000   \n",
      "max            31.800000       43.000000       19.300000       21.700000   \n",
      "missing%        0.542629        0.542629        0.704322        0.704322   \n",
      "\n",
      "                pt_min        pt_max   urineoutput  sofa_coagulation  \\\n",
      "count     32345.000000  32345.000000  35073.000000      36235.000000   \n",
      "mean         14.944678     17.063756   1914.991284          0.481109   \n",
      "std           6.630633     11.251566   1266.887914          0.825034   \n",
      "min           8.000000      8.000000 -14850.000000          0.000000   \n",
      "25%          11.900000     12.300000   1050.000000          0.000000   \n",
      "50%          13.100000     13.900000   1667.000000          0.000000   \n",
      "75%          15.100000     16.800000   2500.000000          1.000000   \n",
      "max         140.300000    154.600000  31016.000000          4.000000   \n",
      "missing%     11.356847     11.356847      3.880622          0.696100   \n",
      "\n",
      "          sofa_cardiovascular      sofa_cns    sofa_renal  \\\n",
      "count            36402.000000  36468.000000  36467.000000   \n",
      "mean                 1.060381      0.915433      0.826501   \n",
      "std                  0.972511      1.050761      1.201510   \n",
      "min                  0.000000      0.000000      0.000000   \n",
      "25%                  1.000000      0.000000      0.000000   \n",
      "50%                  1.000000      1.000000      0.000000   \n",
      "75%                  1.000000      1.000000      1.000000   \n",
      "max                  4.000000      4.000000      4.000000   \n",
      "missing%             0.238428      0.057552      0.060292   \n",
      "\n",
      "          charlson_comorbidity_index  gender  outcome  \n",
      "count                   36489.000000     NaN      NaN  \n",
      "mean                        5.798104     NaN      NaN  \n",
      "std                         3.014789     NaN      NaN  \n",
      "min                         0.000000     NaN      NaN  \n",
      "25%                         4.000000     NaN      NaN  \n",
      "50%                         6.000000     NaN      NaN  \n",
      "75%                         8.000000     NaN      NaN  \n",
      "max                        20.000000     NaN      NaN  \n",
      "missing%                    0.000000     0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "base_describe = df.describe()\n",
    "\n",
    "df_length = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "missing_percent = pd.DataFrame((missing_count / df_length) * 100).T\n",
    "missing_percent = missing_percent.rename(index = lambda i: \"missing%\")\n",
    "missing_describe = pd.concat([base_describe, missing_percent], ignore_index=False)\n",
    "\n",
    "missing_less_40p = missing_describe.T\n",
    "missing_less_40p = missing_less_40p[missing_less_40p[\"missing%\"] <= 40].T\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(missing_less_40p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b672a56",
   "metadata": {},
   "source": [
    "**Both genders Missing <=40% extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e2e03723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lactate_min', 'lactate_max', 'ph_min', 'ph_max', 'chloride_min',\n",
      "       'chloride_max', 'calcium_min', 'calcium_max', 'sodium_min',\n",
      "       'sodium_max', 'total_protein_max', 'total_protein_min', 'alt_max',\n",
      "       'alt_min', 'alp_max', 'alp_min', 'ast_min', 'ast_max',\n",
      "       'bilirubin_total_max', 'bilirubin_total_min', 'bilirubin_direct_max',\n",
      "       'bilirubin_direct_min', 'bilirubin_indirect_max',\n",
      "       'bilirubin_indirect_min', 'sofa_respiration', 'sofa_liver'],\n",
      "      dtype='object')\n",
      "      gender        age  heart_rate_min  heart_rate_max  heart_rate_mean  \\\n",
      "0          M  54.550390            93.0           115.0       103.500000   \n",
      "1          M  86.324653            50.0            61.0        54.333333   \n",
      "2          M  40.270146            70.0           105.0        83.434783   \n",
      "3          M  73.383547            68.0            98.0        83.880000   \n",
      "4          M  70.724748            77.0            95.0        85.771429   \n",
      "...      ...        ...             ...             ...              ...   \n",
      "36484      F  84.952721            59.0            80.0        68.538462   \n",
      "36485      F  30.583263            59.0           104.0        79.954545   \n",
      "36486      F  60.095765            71.0            94.0        82.625000   \n",
      "36487      M  78.847051            63.0            86.0        72.836735   \n",
      "36488      M  32.783457            86.0           103.0        94.000000   \n",
      "\n",
      "       mbp_min  mbp_max    mbp_mean  sbp_min  sbp_max    sbp_mean  dbp_min  \\\n",
      "0         57.0    100.0   82.733333     87.0    163.0  125.433333     30.0   \n",
      "1         61.0     93.0   71.695652     95.0    141.0  109.434783     49.0   \n",
      "2         66.0     92.0   76.695652     94.0    129.0  111.130435     55.0   \n",
      "3         74.0    101.0   84.694444     83.0    148.0  122.166667     53.0   \n",
      "4         30.0     90.0   62.657143     52.0    129.0   90.028571     25.0   \n",
      "...        ...      ...         ...      ...      ...         ...      ...   \n",
      "36484      2.0     95.0   74.346154    109.0    152.0  128.076923     46.0   \n",
      "36485     67.0     91.0   77.820000     94.0    140.0  114.416667     47.0   \n",
      "36486     51.0     92.0   61.772727     90.0    120.0  104.608696     38.0   \n",
      "36487    113.0    121.0  117.000000    148.0    219.0  165.500000     70.0   \n",
      "36488     83.0    118.0   99.916667     97.0    176.0  144.375000     76.0   \n",
      "\n",
      "       dbp_max   dbp_mean  temperature_min  temperature_max  temperature_mean  \\\n",
      "0         83.0  65.600000            36.78            37.56         37.055000   \n",
      "1         85.0  59.652174            36.39            36.94         36.798000   \n",
      "2         81.0  67.173913            36.50            37.28         36.796667   \n",
      "3         93.0  66.722222            36.67            36.83         36.750000   \n",
      "4         80.0  50.771429            36.28            38.11         37.022857   \n",
      "...        ...        ...              ...              ...               ...   \n",
      "36484     65.0  55.961538            35.39            36.00         35.676667   \n",
      "36485     78.0  60.125000            36.67            37.28         37.112500   \n",
      "36486     86.0  50.695652            36.67            37.44         37.016667   \n",
      "36487     94.0  82.576923            36.67            37.00         36.834286   \n",
      "36488    103.0  86.916667            36.44            37.72         36.861667   \n",
      "\n",
      "       glucose_min  glucose_max  wbc_min  wbc_max  creatinine_min  \\\n",
      "0            112.0        122.0     11.6     11.6             1.2   \n",
      "1            103.0        356.0      7.4      8.4             1.4   \n",
      "2            108.0        115.0      4.3      7.0             0.6   \n",
      "3            149.0        156.0     13.0     18.1             1.3   \n",
      "4            102.0        104.0      9.4     11.7             3.4   \n",
      "...            ...          ...      ...      ...             ...   \n",
      "36484        188.0        296.0     17.1     19.4             1.6   \n",
      "36485        188.0        188.0     19.0     19.0             1.0   \n",
      "36486        129.0        155.0      9.6     12.5             0.5   \n",
      "36487        133.0        152.0      7.1      7.8             1.1   \n",
      "36488         73.0        712.0      9.6     10.3             4.0   \n",
      "\n",
      "       creatinine_max  hemoglobin_min  hemoglobin_max  pt_min  pt_max  \\\n",
      "0                 1.7             8.9             8.9    13.2    13.7   \n",
      "1                 1.5            12.6            13.3     9.9    11.1   \n",
      "2                 0.7             6.9             7.1    15.2    15.3   \n",
      "3                 1.6            11.8            12.8     NaN     NaN   \n",
      "4                 4.0            10.2            12.7    12.6    13.4   \n",
      "...               ...             ...             ...     ...     ...   \n",
      "36484             1.8            11.3            12.0    12.5    12.5   \n",
      "36485             1.0            11.5            11.5    12.7    12.7   \n",
      "36486             0.6             8.8             9.6    15.4    79.7   \n",
      "36487             1.1            11.6            12.8    13.3    13.3   \n",
      "36488             9.9            12.3            12.9     NaN     NaN   \n",
      "\n",
      "       urineoutput  sofa_coagulation  sofa_cardiovascular  sofa_cns  \\\n",
      "0           3459.0               0.0                  1.0       0.0   \n",
      "1           2020.0               1.0                  1.0       1.0   \n",
      "2           3050.0               1.0                  1.0       1.0   \n",
      "3           1592.0               0.0                  0.0       0.0   \n",
      "4            339.0               0.0                  4.0       1.0   \n",
      "...            ...               ...                  ...       ...   \n",
      "36484        697.0               0.0                  1.0       4.0   \n",
      "36485       2000.0               0.0                  1.0       1.0   \n",
      "36486       3500.0               0.0                  1.0       0.0   \n",
      "36487       1900.0               0.0                  0.0       1.0   \n",
      "36488          NaN               0.0                  0.0       1.0   \n",
      "\n",
      "       sofa_renal  charlson_comorbidity_index  outcome  \n",
      "0             1.0                           3    False  \n",
      "1             1.0                           8    False  \n",
      "2             0.0                           4    False  \n",
      "3             1.0                           6    False  \n",
      "4             3.0                          10    False  \n",
      "...           ...                         ...      ...  \n",
      "36484         1.0                          10    False  \n",
      "36485         0.0                           0    False  \n",
      "36486         0.0                           3    False  \n",
      "36487         0.0                           5    False  \n",
      "36488         4.0                           5    False  \n",
      "\n",
      "[36489 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "base_describe = df.describe()\n",
    "\n",
    "df_length = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "missing_percent = pd.DataFrame((missing_count / df_length) * 100).T\n",
    "missing_percent = missing_percent.rename(index = lambda i: \"missing%\")\n",
    "missing_describe = pd.concat([base_describe, missing_percent], ignore_index=False)\n",
    "\n",
    "missing_more_40p = missing_describe.T\n",
    "missing_more_40p = missing_more_40p[missing_more_40p[\"missing%\"] > 40].T\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(missing_more_40p.columns)\n",
    "\n",
    "col_missing_more_40p = list(missing_more_40p.columns)\n",
    "\n",
    "data_missing_less_40p = df.loc[:, ~df.columns.isin(col_missing_more_40p)]\n",
    "\n",
    "print(data_missing_less_40p)\n",
    "\n",
    "data_missing_less_40p.to_csv('Assignment_1_data_missing_less_40p.csv', index=False)  #comment to not write data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ac1fa",
   "metadata": {},
   "source": [
    "**Both genders Missing <=40% describe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a7c662bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   age  heart_rate_min  heart_rate_max  heart_rate_mean  \\\n",
      "count     36489.000000    36417.000000    36417.000000     36417.000000   \n",
      "mean         65.907162       70.935003      103.109572        84.855578   \n",
      "std          16.797498       15.064109       20.682937        15.977454   \n",
      "min          18.002527        9.000000       36.000000        28.500000   \n",
      "25%          55.549252       60.000000       88.000000        73.321429   \n",
      "50%          67.439033       70.000000      101.000000        83.500000   \n",
      "75%          78.729524       80.000000      115.000000        95.250000   \n",
      "max         102.865603      163.000000      295.000000       174.740741   \n",
      "missing%      0.000000        0.197320        0.197320         0.197320   \n",
      "\n",
      "               mbp_min       mbp_max      mbp_mean       sbp_min  \\\n",
      "count     36401.000000  36401.000000  36401.000000  36343.000000   \n",
      "mean         60.429777    105.484634     79.255689     94.449898   \n",
      "std          13.347348     23.346984     11.758700     16.705217   \n",
      "min           0.830000     51.000000     42.513889      2.000000   \n",
      "25%          53.000000     91.000000     70.896552     83.500000   \n",
      "50%          60.000000    102.000000     77.851852     93.000000   \n",
      "75%          68.000000    115.000000     86.382353    104.000000   \n",
      "max         133.000000    299.000000    151.529412    184.000000   \n",
      "missing%      0.241169      0.241169      0.241169      0.400121   \n",
      "\n",
      "               sbp_max      sbp_mean       dbp_min       dbp_max  \\\n",
      "count     36343.000000  36343.000000  36341.000000  36341.000000   \n",
      "mean        147.691412    119.757827     47.379860     90.387455   \n",
      "std          22.855348     17.220898     11.853837     20.183779   \n",
      "min          49.000000     40.000000      1.000000     29.000000   \n",
      "25%         132.000000    107.096464     40.000000     76.000000   \n",
      "50%         146.000000    117.678571     47.000000     88.000000   \n",
      "75%         161.000000    130.649616     54.000000    101.000000   \n",
      "max         352.000000    206.388889    113.000000    273.000000   \n",
      "missing%      0.400121      0.400121      0.405602      0.405602   \n",
      "\n",
      "              dbp_mean  temperature_min  temperature_max  temperature_mean  \\\n",
      "count     36341.000000     36126.000000     36126.000000      36126.000000   \n",
      "mean         64.540082        36.348090        37.296027         36.813596   \n",
      "std          11.661638         0.548462         0.622069          0.416853   \n",
      "min          29.000000        22.000000        33.400000         33.191304   \n",
      "25%          56.344828        36.170000        36.940000         36.601429   \n",
      "50%          63.304348        36.440000        37.170000         36.792857   \n",
      "75%          71.575758        36.670000        37.560000         37.010000   \n",
      "max         130.388889        38.560000        42.000000         39.517692   \n",
      "missing%      0.405602         0.994820         0.994820          0.994820   \n",
      "\n",
      "           glucose_min   glucose_max       wbc_min       wbc_max  \\\n",
      "count     36191.000000  36191.000000  36235.000000  36235.000000   \n",
      "mean        117.663729    167.322815     10.181060     13.145738   \n",
      "std          39.923837    113.182968      7.792171     11.082715   \n",
      "min           7.000000      7.000000      0.100000      0.100000   \n",
      "25%          93.000000    113.000000      6.600000      8.300000   \n",
      "50%         109.000000    137.000000      9.000000     11.400000   \n",
      "75%         132.000000    178.000000     12.200000     15.700000   \n",
      "max         575.000000   2440.000000    300.400000    407.200000   \n",
      "missing%      0.816684      0.816684      0.696100      0.696100   \n",
      "\n",
      "          creatinine_min  creatinine_max  hemoglobin_min  hemoglobin_max  \\\n",
      "count       36291.000000    36291.000000    36232.000000    36232.000000   \n",
      "mean            1.330352        1.591678       10.293279       11.393038   \n",
      "std             1.466693        1.847420        2.280191        2.172428   \n",
      "min             0.100000        0.100000        2.200000        3.700000   \n",
      "25%             0.700000        0.800000        8.600000        9.800000   \n",
      "50%             0.900000        1.000000       10.300000       11.300000   \n",
      "75%             1.300000        1.600000       11.900000       12.900000   \n",
      "max            31.800000       43.000000       19.300000       21.700000   \n",
      "missing%        0.542629        0.542629        0.704322        0.704322   \n",
      "\n",
      "                pt_min        pt_max   urineoutput  sofa_coagulation  \\\n",
      "count     32345.000000  32345.000000  35073.000000      36235.000000   \n",
      "mean         14.944678     17.063756   1914.991284          0.481109   \n",
      "std           6.630633     11.251566   1266.887914          0.825034   \n",
      "min           8.000000      8.000000 -14850.000000          0.000000   \n",
      "25%          11.900000     12.300000   1050.000000          0.000000   \n",
      "50%          13.100000     13.900000   1667.000000          0.000000   \n",
      "75%          15.100000     16.800000   2500.000000          1.000000   \n",
      "max         140.300000    154.600000  31016.000000          4.000000   \n",
      "missing%     11.356847     11.356847      3.880622          0.696100   \n",
      "\n",
      "          sofa_cardiovascular      sofa_cns    sofa_renal  \\\n",
      "count            36402.000000  36468.000000  36467.000000   \n",
      "mean                 1.060381      0.915433      0.826501   \n",
      "std                  0.972511      1.050761      1.201510   \n",
      "min                  0.000000      0.000000      0.000000   \n",
      "25%                  1.000000      0.000000      0.000000   \n",
      "50%                  1.000000      1.000000      0.000000   \n",
      "75%                  1.000000      1.000000      1.000000   \n",
      "max                  4.000000      4.000000      4.000000   \n",
      "missing%             0.238428      0.057552      0.060292   \n",
      "\n",
      "          charlson_comorbidity_index  gender  outcome  \n",
      "count                   36489.000000     NaN      NaN  \n",
      "mean                        5.798104     NaN      NaN  \n",
      "std                         3.014789     NaN      NaN  \n",
      "min                         0.000000     NaN      NaN  \n",
      "25%                         4.000000     NaN      NaN  \n",
      "50%                         6.000000     NaN      NaN  \n",
      "75%                         8.000000     NaN      NaN  \n",
      "max                        20.000000     NaN      NaN  \n",
      "missing%                    0.000000     0.0      0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "df = pd.read_csv('Assignment_1_data_working.csv')\n",
    "\n",
    "base_describe = df.describe()\n",
    "\n",
    "df_length = len(df)\n",
    "missing_count = df.isna().sum()\n",
    "missing_percent = pd.DataFrame((missing_count / df_length) * 100).T\n",
    "missing_percent = missing_percent.rename(index = lambda i: \"missing%\")\n",
    "missing_describe = pd.concat([base_describe, missing_percent], ignore_index=False)\n",
    "\n",
    "missing_more_40p = missing_describe.T\n",
    "missing_more_40p = missing_more_40p[missing_more_40p[\"missing%\"] > 40].T\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "#print(missing_more_40p.columns)\n",
    "\n",
    "col_missing_more_40p = list(missing_more_40p.columns)\n",
    "\n",
    "data_missing_less_40p = df.loc[:, ~df.columns.isin(col_missing_more_40p)]\n",
    "\n",
    "#print(data_missing_less_40p)\n",
    "\n",
    "data_missing_less_40p_describe = data_missing_less_40p.describe()\n",
    "data_missing_less_40p_length = len(data_missing_less_40p)\n",
    "missing_count = data_missing_less_40p.isna().sum()\n",
    "missing_percent = pd.DataFrame((missing_count / data_missing_less_40p_length) * 100).T\n",
    "missing_percent = missing_percent.rename(index = lambda i: \"missing%\")\n",
    "missing_describe = pd.concat([data_missing_less_40p_describe, missing_percent], ignore_index=False)\n",
    "\n",
    "print(missing_describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c628520",
   "metadata": {},
   "source": [
    "**gender chi sq outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38bed319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outcome  False  True\n",
      "gender              \n",
      "F        16079   530\n",
      "M        19081   799\n",
      "(17.680150102526696, 2.6133963118715167e-05, 1, array([[16004.06807531,   604.93192469],\n",
      "       [19155.93192469,   724.06807531]]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "data_missing_less_40p = pd.read_csv('Assignment_1_data_missing_less_40p.csv')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "gender_contig = pd.crosstab(data_missing_less_40p['gender'], data_missing_less_40p['outcome'], rownames=None, colnames=None)\n",
    "\n",
    "\n",
    "print(gender_contig)\n",
    "\n",
    "chi2_contig = sp.stats.chi2_contingency(gender_contig, lambda_=None, correction=False)\n",
    "\n",
    "print(chi2_contig) # chi2_contingency() returns chi(which is a test statistic), p(which is the p-value of the test), dof(which is the degree of freedom) and expected(Frequencies to expect)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc986753",
   "metadata": {},
   "source": [
    "**mann whitney u test for contiuous variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0d7be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MannwhitneyuResult(statistic=22866912.5, pvalue=0.18742596335306927)\n",
      "\n",
      "\n",
      "The age MannwhitneyuResult(statistic=22866912.5, pvalue=0.18742596335306927)\n",
      "\n",
      "\n",
      "The heart_rate_min MannwhitneyuResult(statistic=26512086.0, pvalue=1.9302219013611404e-17)\n",
      "\n",
      "\n",
      "The heart_rate_max MannwhitneyuResult(statistic=26392564.0, pvalue=2.8564472986997756e-16)\n",
      "\n",
      "\n",
      "The heart_rate_mean MannwhitneyuResult(statistic=26641458.5, pvalue=9.583854719027351e-19)\n",
      "\n",
      "\n",
      "The mbp_min MannwhitneyuResult(statistic=21738267.0, pvalue=3.061227285026849e-05)\n",
      "\n",
      "\n",
      "The mbp_max MannwhitneyuResult(statistic=24073979.5, pvalue=0.040910961269518084)\n",
      "\n",
      "\n",
      "The mbp_mean MannwhitneyuResult(statistic=22611587.5, pvalue=0.06504023208932269)\n",
      "\n",
      "\n",
      "The sbp_min MannwhitneyuResult(statistic=21333941.5, pvalue=6.446732267820086e-07)\n",
      "\n",
      "\n",
      "The sbp_max MannwhitneyuResult(statistic=24228004.0, pvalue=0.00606764540227739)\n",
      "\n",
      "\n",
      "The sbp_mean MannwhitneyuResult(statistic=22358357.5, pvalue=0.02485621168609073)\n",
      "\n",
      "\n",
      "The dbp_min MannwhitneyuResult(statistic=21810216.5, pvalue=0.00021230390177748063)\n",
      "\n",
      "\n",
      "The dbp_max MannwhitneyuResult(statistic=23346956.0, pvalue=0.6912450333333946)\n",
      "\n",
      "\n",
      "The dbp_mean MannwhitneyuResult(statistic=22277773.0, pvalue=0.014080605633792086)\n",
      "\n",
      "\n",
      "The temperature_min MannwhitneyuResult(statistic=23400556.0, pvalue=0.3309141410419175)\n",
      "\n",
      "\n",
      "The temperature_max MannwhitneyuResult(statistic=25119196.0, pvalue=2.2713427290530365e-08)\n",
      "\n",
      "\n",
      "The temperature_mean MannwhitneyuResult(statistic=24586435.5, pvalue=3.2540147085588545e-05)\n",
      "\n",
      "\n",
      "The glucose_min MannwhitneyuResult(statistic=24093230.5, pvalue=0.0077110959054774155)\n",
      "\n",
      "\n",
      "The glucose_max MannwhitneyuResult(statistic=25212652.5, pvalue=1.4839903866819102e-08)\n",
      "\n",
      "\n",
      "The wbc_min MannwhitneyuResult(statistic=25430986.5, pvalue=7.155206588896983e-10)\n",
      "\n",
      "\n",
      "The wbc_max MannwhitneyuResult(statistic=25795595.5, pvalue=9.459737475532373e-13)\n",
      "\n",
      "\n",
      "The creatinine_min MannwhitneyuResult(statistic=25463069.5, pvalue=9.774137745464385e-10)\n",
      "\n",
      "\n",
      "The creatinine_max MannwhitneyuResult(statistic=25815945.0, pvalue=1.7575011425539596e-12)\n",
      "\n",
      "\n",
      "The hemoglobin_min MannwhitneyuResult(statistic=21797675.0, pvalue=0.00044671314829464745)\n",
      "\n",
      "\n",
      "The hemoglobin_max MannwhitneyuResult(statistic=22269633.0, pvalue=0.024617088529275938)\n",
      "\n",
      "\n",
      "The pt_min MannwhitneyuResult(statistic=22124005.0, pvalue=9.543483368973402e-17)\n",
      "\n",
      "\n",
      "The pt_max MannwhitneyuResult(statistic=21979037.5, pvalue=3.777059125828587e-15)\n",
      "\n",
      "\n",
      "The urineoutput MannwhitneyuResult(statistic=18571861.0, pvalue=8.924916236724555e-20)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "data_missing_less_40p = pd.read_csv('Assignment_1_data_missing_less_40p.csv')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "noncontinuous_var = ['gender', 'sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index']\n",
    "\n",
    "data_continuous = data_missing_less_40p.loc[:, ~data_missing_less_40p.columns.isin(noncontinuous_var)]\n",
    "\n",
    "\n",
    "\n",
    "select = data_continuous[['age', 'outcome']]\n",
    "##age_outcome = select[select['outcome'] == True]\n",
    "age_true = select[select['outcome'] == True]['age']\n",
    "age_true = pd.DataFrame(data=age_true).T\n",
    "age_true = age_true.loc['age'].values.flatten().tolist()\n",
    "\n",
    "select = data_continuous[['age', 'outcome']]\n",
    "#age_outcome = select[select['outcome'] == False]\n",
    "age_false = select[select['outcome'] == False]['age']\n",
    "age_false = pd.DataFrame(data=age_false).T\n",
    "age_false = age_false.loc['age'].values.flatten().tolist()\n",
    "\n",
    "age_mann = sp.stats.mannwhitneyu(age_true, age_false, use_continuity=True, nan_policy='omit')\n",
    "\n",
    "#print('age mann whitney outcome:', age_mann)\n",
    "#print('\\n')\n",
    "\n",
    "col_names = data_continuous.loc[:, ~data_continuous.columns.isin(['outcome'])]\n",
    "col_names = list(col_names)\n",
    "\n",
    "\n",
    "def describeMann(data_table, variable, treatment, treat_label1, treat_label2):\n",
    "    select = data_table[[variable, treatment]]\n",
    "    var_true = select[select[treatment] == treat_label1][variable]\n",
    "    var_true = pd.DataFrame(data=var_true).T\n",
    "    var_true = var_true.loc[variable].values.flatten().tolist()\n",
    "\n",
    "    select2 = data_table[[variable, treatment]]\n",
    "    var_false = select2[select2[treatment] == treat_label2][variable]\n",
    "    var_false = pd.DataFrame(data=var_false).T\n",
    "    var_false = var_false.loc[variable].values.flatten().tolist()\n",
    "\n",
    "    var_mann = sp.stats.mannwhitneyu(var_true, var_false, use_continuity=True, nan_policy='omit')\n",
    "    \n",
    "    return var_mann\n",
    "\n",
    "for i in col_names:\n",
    "    print('The ' + i + ' ' + str(describeMann(data_continuous, i, 'outcome', True, False)))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2cb1f",
   "metadata": {},
   "source": [
    "**non_continuous chi sq outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f62681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gender chi2 contingency is p-value: 2.6133963118715167e-05 details: chi / p / dof / expected (17.680150102526696, 2.6133963118715167e-05, 1, array([[16004.06807531,   604.93192469],\n",
      "       [19155.93192469,   724.06807531]]))\n",
      "\n",
      "\n",
      "The sofa_coagulation chi2 contingency is p-value: 1.1320438384029352e-10 details: chi / p / dof / expected (52.410471333877226, 1.1320438384029352e-10, 4, array([[2.38206034e+04, 9.03396605e+02],\n",
      "       [6.91090391e+03, 2.62096095e+02],\n",
      "       [2.94529949e+03, 1.11700511e+02],\n",
      "       [9.42264606e+02, 3.57353940e+01],\n",
      "       [2.91928605e+02, 1.10713951e+01]]))\n",
      "\n",
      "\n",
      "The sofa_cardiovascular chi2 contingency is p-value: 1.8641046624750227e-09 details: chi / p / dof / expected (46.581146637345206, 1.8641046624750227e-09, 4, array([[7.72238050e+03, 2.92619499e+02],\n",
      "       [2.33213001e+04, 8.83699934e+02],\n",
      "       [2.75558431e+02, 1.04415691e+01],\n",
      "       [1.69670768e+03, 6.42923191e+01],\n",
      "       [2.05705332e+03, 7.79466788e+01]]))\n",
      "\n",
      "\n",
      "The sofa_cns chi2 contingency is p-value: 0.0 details: chi / p / dof / expected (1698.1935411710479, 0.0, 4, array([[14783.85644949,   559.14355051],\n",
      "       [13522.56021718,   511.43978282],\n",
      "       [ 3098.79960513,   117.20039487],\n",
      "       [ 2487.90440935,    94.09559065],\n",
      "       [ 1245.87931885,    47.12068115]]))\n",
      "\n",
      "\n",
      "The sofa_renal chi2 contingency is p-value: 1.2640045906478063e-10 details: chi / p / dof / expected (52.18151732675659, 1.2640045906478063e-10, 4, array([[20093.99873859,   760.00126141],\n",
      "       [ 7676.65138344,   290.34861656],\n",
      "       [ 2952.3358653 ,   111.6641347 ],\n",
      "       [ 2199.7985576 ,    83.2014424 ],\n",
      "       [ 2215.21545507,    83.78454493]]))\n",
      "\n",
      "\n",
      "The charlson_comorbidity_index chi2 contingency is p-value: 0.0015583410439132161 details: chi / p / dof / expected (43.886811306279746, 0.0015583410439132161, 20, array([[1.26517800e+03, 4.78220012e+01],\n",
      "       [1.44151278e+03, 5.44872153e+01],\n",
      "       [2.02351394e+03, 7.64860643e+01],\n",
      "       [3.06803256e+03, 1.15967442e+02],\n",
      "       [4.45076708e+03, 1.68232920e+02],\n",
      "       [4.85836060e+03, 1.83639398e+02],\n",
      "       [4.45943928e+03, 1.68560717e+02],\n",
      "       [3.86587520e+03, 1.46124805e+02],\n",
      "       [3.12873798e+03, 1.18262024e+02],\n",
      "       [2.51782948e+03, 9.51705171e+01],\n",
      "       [1.81634465e+03, 6.86553482e+01],\n",
      "       [1.02331990e+03, 3.86800954e+01],\n",
      "       [5.84891885e+02, 2.21081148e+01],\n",
      "       [3.41106635e+02, 1.28933651e+01],\n",
      "       [1.49354600e+02, 5.64539998e+00],\n",
      "       [9.25034942e+01, 3.49650580e+00],\n",
      "       [4.23974348e+01, 1.60256516e+00],\n",
      "       [2.40894516e+01, 9.10548384e-01],\n",
      "       [3.85431226e+00, 1.45687742e-01],\n",
      "       [9.63578065e-01, 3.64219354e-02],\n",
      "       [1.92715613e+00, 7.28438708e-02]]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "data_missing_less_40p = pd.read_csv('Assignment_1_data_missing_less_40p.csv')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index']\n",
    "\n",
    "def chisq(data_table, variable, treatment):\n",
    "    contig = pd.crosstab(data_table[variable], data_table[treatment], rownames=None, colnames=None)\n",
    "    \n",
    "    chi2_contig = sp.stats.chi2_contingency(contig, lambda_=None, correction=False)\n",
    "    return chi2_contig # chi2_contingency() returns chi(which is a test statistic), p(which is the p-value of the test), dof(which is the degree of freedom) and expected(Frequencies to expect)\n",
    "\n",
    "for i in noncontinuous_var:\n",
    "    print('The ' + i + ' chi2 contingency is p-value: ' + str(chisq(data_missing_less_40p, i, 'outcome')[1]) + ' details: chi / p / dof / expected '+ str(chisq(data_missing_less_40p, i, 'outcome')))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3e891",
   "metadata": {},
   "source": [
    "**SVM no vanilla non-continuous var**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c9fbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2836\\1142082646.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    191\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    112\u001b[0m         ):\n\u001b[0;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"infinity\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"NaN, infinity\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_missing_less_40p = pd.read_csv('Assignment_1_data_missing_less_40p.csv')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "noncontinuous_select = data_missing_less_40p[noncontinuous_var]\n",
    "\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_select.to_csv('noncontinuous_select.csv', index=False)  #comment to not write data\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv')\n",
    "\n",
    "\n",
    "#X = [[0, 0], [1, 1]]\n",
    "#y = [0, 1]\n",
    "#clf = svm.SVC()\n",
    "#clf.fit(X, y)\n",
    "\n",
    "print(noncontinuous_select['sofa_coagulation'].to_numpy())\n",
    "\n",
    "#X = noncontinuous_select[:-2]\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "y = noncontinuous_select['outcome'].to_numpy()\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "#X = np.reshape(noncontinuous_select['sofa_coagulation'], -1, 1)\n",
    "#y = np.reshape(noncontinuous_select['outcome'], -1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "#stepsize in the mesh, it alters the accuracy of the plotprint\n",
    "#to better understand it, just play with the value, change it and print it\n",
    "h = .01\n",
    "#create the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "# create the title that will be shown on the plot\n",
    "titles = ['Linear kernel','RBF kernel','Polynomial kernel','Sigmoid kernel']\n",
    "\n",
    "for i, clf in enumerate((linear, rbf, poly, sig)): #credit\n",
    "    #defines how many plots: 2 rows, 2columns=> leading to 4 plots\n",
    "    plt.subplot(2, 2, i + 1) #i+1 is the index\n",
    "    #space between plots\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4) \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.PuBuGn, alpha=0.7)\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.PuBuGn,     edgecolors='grey')\n",
    "    plt.xlabel('sofa_coagulation')\n",
    "    plt.ylabel('outcome')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c59e8",
   "metadata": {},
   "source": [
    "coding for smote and impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30a2a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "\n",
    "\n",
    "#X = [[0, 0], [1, 1]]\n",
    "#y = [0, 1]\n",
    "#clf = svm.SVC()\n",
    "#clf.fit(X, y)\n",
    "\n",
    "#print(noncontinuous_select['sofa_coagulation'].to_numpy())\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "knn_imputed_noncontin = pd.read_csv('knn_imputed_noncontin_var.csv', index_col=False)\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_noncontin, pd.DataFrame(noncontinuous_select[['gender','charlson_comorbidity_index', 'outcome']]).reset_index()], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "                                   \n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "imp_median_var.to_csv('imp_median_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "median_imputed_noncontin = pd.read_csv('median_imputed_noncontin_var.csv', index_col=False)\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_noncontin, pd.DataFrame(noncontinuous_select[['gender','charlson_comorbidity_index', 'outcome']]).reset_index()], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "\n",
    "\n",
    "#X = median_imputed_noncontin[]\n",
    "\n",
    "#s_y = noncontinuous_select['outcome']\n",
    "\n",
    "# transform the dataset\n",
    "#oversample = SMOTE()\n",
    "#X, s_y = oversample.fit_resample(X, s_y)\n",
    "# summarize the new class distribution\n",
    "#counter = Counter(s_y)\n",
    "#print(counter)\n",
    "# scatter plot of examples by class label\n",
    "#for label, _ in counter.items():\n",
    "# row_ix = np.where(s_y == label)[0]\n",
    "# plt.scatter(X, s_y, label=str(label))\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#X = np.reshape(noncontinuous_select['sofa_coagulation'], -1, 1)\n",
    "#y = np.reshape(noncontinuous_select['outcome'], -1, 1)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00490d",
   "metadata": {},
   "source": [
    "Single var Impute and Multi SMOTE non-continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "40469911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "ordEnc = OrdinalEncoder()\n",
    "encoded_gender = median_imputed_noncontin['gender'].to_numpy()\n",
    "encoded_gender = encoded_gender.reshape(-1, 1)\n",
    "encoded_gender = pd.DataFrame(ordEnc.fit_transform(encoded_gender), columns = ['gender']) #1 male, 0 female\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "                                   \n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "def smote_this(table, lst, y_var):    \n",
    "    X = table[lst]\n",
    "    y = table[y_var].to_numpy()\n",
    "    y = y.ravel()\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    oversample = SMOTE()\n",
    "    X, y = oversample.fit_resample(X, y)    \n",
    "    array_X = pd.DataFrame(X)\n",
    "    array_y = pd.DataFrame(X)\n",
    "    \n",
    "    output = pd.concat([array_X, array_y], axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "smote_noncontin = smote_this(median_imputed_noncontin, ['sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index'] ,'outcome')\n",
    "smote_noncontin.to_csv('smote_noncontin.csv', index=False)  #comment to not write data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e7e4f",
   "metadata": {},
   "source": [
    "SVM on noncontin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e98e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "\n",
    "'''\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "ordEnc = OrdinalEncoder()\n",
    "encoded_gender = noncontinuous_select['gender'].to_numpy()\n",
    "encoded_gender = encoded_gender.reshape(-1, 1)\n",
    "encoded_gender = pd.DataFrame(ordEnc.fit_transform(encoded_gender), columns = ['gender']) #1 male, 0 female\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "def smotenThis(table, lst, y_var):    \n",
    "    X = table[lst]\n",
    "    y = table[y_var].to_numpy()\n",
    "    y = y.ravel()\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    oversample = SMOTEN()\n",
    "    X, y = oversample.fit_resample(X, y)    \n",
    "    array_X = pd.DataFrame(X)\n",
    "    array_y = pd.DataFrame(y, columns = [y_var])\n",
    "    \n",
    "    output = pd.concat([array_X, array_y], axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "smoten_noncontin = smotenThis(median_imputed_noncontin, ['sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index'] ,'outcome')\n",
    "smoten_noncontin.to_csv('smoten_noncontin.csv', index=False)  #comment to not write data\n",
    "'''\n",
    "\n",
    "#median_imputed_noncontin = pd.read_csv('median_imputed_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('linear SVM')\n",
    "print(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rbf = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('rbf SVM')\n",
    "print(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_poly = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('polynomial SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_sig = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('sigmoid SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c99821",
   "metadata": {},
   "source": [
    "feature selection on noncontin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e871db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.65      0.82      0.72      6902\n",
      " Intubation True       0.77      0.57      0.65      7162\n",
      "\n",
      "        accuracy                           0.69     14064\n",
      "       macro avg       0.71      0.69      0.69     14064\n",
      "    weighted avg       0.71      0.69      0.69     14064\n",
      "\n",
      "rbf SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.74      0.77      0.75      6902\n",
      " Intubation True       0.77      0.74      0.75      7162\n",
      "\n",
      "        accuracy                           0.75     14064\n",
      "       macro avg       0.75      0.75      0.75     14064\n",
      "    weighted avg       0.75      0.75      0.75     14064\n",
      "\n",
      "polynomial SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.66      0.80      0.72      6902\n",
      " Intubation True       0.76      0.60      0.67      7162\n",
      "\n",
      "        accuracy                           0.70     14064\n",
      "       macro avg       0.71      0.70      0.70     14064\n",
      "    weighted avg       0.71      0.70      0.70     14064\n",
      "\n",
      "sigmoid SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.66      0.80      0.72      6902\n",
      " Intubation True       0.76      0.60      0.67      7162\n",
      "\n",
      "        accuracy                           0.70     14064\n",
      "       macro avg       0.71      0.70      0.70     14064\n",
      "    weighted avg       0.71      0.70      0.70     14064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "\n",
    "'''\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "ordEnc = OrdinalEncoder()\n",
    "encoded_gender = noncontinuous_select['gender'].to_numpy()\n",
    "encoded_gender = encoded_gender.reshape(-1, 1)\n",
    "encoded_gender = pd.DataFrame(ordEnc.fit_transform(encoded_gender), columns = ['gender']) #1 male, 0 female\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "def smotenThis(table, lst, y_var):    \n",
    "    X = table[lst]\n",
    "    y = table[y_var].to_numpy()\n",
    "    y = y.ravel()\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    oversample = SMOTEN()\n",
    "    X, y = oversample.fit_resample(X, y)    \n",
    "    array_X = pd.DataFrame(X)\n",
    "    array_y = pd.DataFrame(y, columns = [y_var])\n",
    "    \n",
    "    output = pd.concat([array_X, array_y], axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "smoten_noncontin = smotenThis(median_imputed_noncontin, ['sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index'] ,'outcome')\n",
    "smoten_noncontin.to_csv('smoten_noncontin.csv', index=False)  #comment to not write data\n",
    "'''\n",
    "\n",
    "#median_imputed_noncontin = pd.read_csv('median_imputed_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "'''\n",
    "X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "y = median_imputed_noncontin['outcome']\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "geneticFeature = GAFeatureSelectionCV(estimator, generations=10) #80 generations is default\n",
    "geneticFeature.fit(X,y)\n",
    "print('Genetic Feature Selection:', X.columns[geneticFeature.support_])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n",
    "sfs.fit(X, y)\n",
    "print('Step Forward Selecition:', sfs.get_support())\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#X = median_imputed_noncontin[['sofa_coagulation', 'sofa_cardiovascular', 'sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index']]\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "X = smoten_noncontin[['sofa_coagulation', 'sofa_cardiovascular', 'sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index']]\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('linear SVM')\n",
    "print(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rbf = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('rbf SVM')\n",
    "print(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_poly = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('polynomial SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_sig = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('sigmoid SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ffe279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t0.670522\t0.072949   \t0.844241   \t0.552688   \n",
      "1  \t100   \t0.730636\t0.0459398  \t0.844297   \t0.580646   \n",
      "2  \t100   \t0.745534\t0.0460126  \t0.844425   \t0.641524   \n",
      "3  \t100   \t0.770821\t0.0541732  \t0.844425   \t0.632935   \n",
      "4  \t100   \t0.779492\t0.050081   \t0.844425   \t0.632935   \n",
      "5  \t100   \t0.789615\t0.0536421  \t0.844425   \t0.59771    \n",
      "6  \t100   \t0.783355\t0.0735378  \t0.844425   \t0.602673   \n",
      "7  \t100   \t0.789107\t0.0649087  \t0.844425   \t0.591283   \n",
      "8  \t100   \t0.792392\t0.0651848  \t0.844468   \t0.59572    \n",
      "9  \t100   \t0.784038\t0.0813574  \t0.844468   \t0.564889   \n",
      "10 \t100   \t0.79987 \t0.0732855  \t0.844525   \t0.580646   \n",
      "11 \t100   \t0.808688\t0.0668096  \t0.844525   \t0.567989   \n",
      "12 \t100   \t0.801598\t0.0644987  \t0.844482   \t0.591283   \n",
      "13 \t100   \t0.805466\t0.0634796  \t0.844468   \t0.6125     \n",
      "14 \t100   \t0.800121\t0.0761803  \t0.84444    \t0.580503   \n",
      "15 \t100   \t0.789591\t0.0822992  \t0.84444    \t0.567989   \n",
      "16 \t100   \t0.802635\t0.06837    \t0.84444    \t0.620592   \n",
      "17 \t100   \t0.792264\t0.0681956  \t0.84444    \t0.564889   \n",
      "18 \t100   \t0.78823 \t0.0677995  \t0.844425   \t0.59572    \n",
      "19 \t100   \t0.779195\t0.0765284  \t0.844397   \t0.567989   \n",
      "20 \t100   \t0.791935\t0.0761077  \t0.844397   \t0.580646   \n",
      "21 \t100   \t0.795845\t0.0588887  \t0.844454   \t0.659272   \n",
      "22 \t100   \t0.805463\t0.0584337  \t0.844454   \t0.59572    \n",
      "23 \t100   \t0.802024\t0.0634835  \t0.844454   \t0.567989   \n",
      "24 \t100   \t0.807003\t0.0517198  \t0.844468   \t0.61314    \n",
      "25 \t100   \t0.798371\t0.0650562  \t0.844425   \t0.580503   \n",
      "26 \t100   \t0.794362\t0.0751084  \t0.844425   \t0.567989   \n",
      "27 \t100   \t0.798065\t0.0736768  \t0.844425   \t0.567989   \n",
      "28 \t100   \t0.797968\t0.0725479  \t0.844425   \t0.567989   \n",
      "29 \t100   \t0.811481\t0.0575381  \t0.844425   \t0.648606   \n",
      "30 \t100   \t0.797373\t0.0778249  \t0.844425   \t0.567989   \n",
      "31 \t100   \t0.791412\t0.0773111  \t0.844425   \t0.564889   \n",
      "32 \t100   \t0.784252\t0.0825402  \t0.844425   \t0.580646   \n",
      "33 \t100   \t0.802342\t0.0761889  \t0.844454   \t0.552688   \n",
      "34 \t100   \t0.790701\t0.0734633  \t0.844454   \t0.575014   \n",
      "35 \t100   \t0.799643\t0.0666245  \t0.844454   \t0.591283   \n",
      "36 \t100   \t0.802218\t0.0656691  \t0.844454   \t0.591283   \n",
      "37 \t100   \t0.796433\t0.0741261  \t0.844454   \t0.591283   \n",
      "38 \t100   \t0.812072\t0.0631024  \t0.844454   \t0.59771    \n",
      "39 \t100   \t0.789757\t0.0819608  \t0.844454   \t0.564889   \n",
      "40 \t100   \t0.804552\t0.066688   \t0.844454   \t0.564889   \n",
      "41 \t100   \t0.801303\t0.0623754  \t0.844454   \t0.580503   \n",
      "42 \t100   \t0.798258\t0.0817428  \t0.84444    \t0.552688   \n",
      "43 \t100   \t0.806187\t0.0647096  \t0.844525   \t0.58696    \n",
      "44 \t100   \t0.801727\t0.0658374  \t0.844454   \t0.580646   \n",
      "45 \t100   \t0.798673\t0.0705278  \t0.844454   \t0.580646   \n",
      "46 \t100   \t0.806503\t0.0706819  \t0.844454   \t0.552688   \n",
      "47 \t100   \t0.802226\t0.0651701  \t0.844482   \t0.580646   \n",
      "48 \t100   \t0.8079  \t0.0574788  \t0.844482   \t0.567989   \n",
      "49 \t100   \t0.806408\t0.0554908  \t0.844482   \t0.6532     \n",
      "50 \t100   \t0.788897\t0.0758341  \t0.844482   \t0.580646   \n",
      "51 \t100   \t0.811336\t0.054537   \t0.844482   \t0.634258   \n",
      "52 \t100   \t0.819813\t0.0427904  \t0.844482   \t0.700782   \n",
      "53 \t100   \t0.81378 \t0.0646538  \t0.844482   \t0.564889   \n",
      "54 \t100   \t0.796263\t0.0737074  \t0.844482   \t0.564889   \n",
      "55 \t100   \t0.803996\t0.0726947  \t0.844482   \t0.580646   \n",
      "56 \t100   \t0.801578\t0.0718583  \t0.844497   \t0.580646   \n",
      "57 \t100   \t0.818811\t0.0503541  \t0.844482   \t0.648606   \n",
      "58 \t100   \t0.803377\t0.0691706  \t0.84444    \t0.580646   \n",
      "59 \t100   \t0.79768 \t0.0818483  \t0.844468   \t0.564889   \n",
      "60 \t100   \t0.813921\t0.0619318  \t0.84444    \t0.580646   \n",
      "61 \t100   \t0.811634\t0.0661882  \t0.84444    \t0.567989   \n",
      "62 \t100   \t0.798414\t0.0862879  \t0.84444    \t0.553427   \n",
      "63 \t100   \t0.80633 \t0.0663724  \t0.84444    \t0.61314    \n",
      "64 \t100   \t0.786335\t0.0805344  \t0.84444    \t0.580646   \n",
      "65 \t100   \t0.784818\t0.0696481  \t0.844425   \t0.61506    \n",
      "66 \t100   \t0.798404\t0.0602469  \t0.844425   \t0.632935   \n",
      "67 \t100   \t0.810894\t0.0611352  \t0.844425   \t0.567989   \n",
      "68 \t100   \t0.801784\t0.0766683  \t0.844425   \t0.580503   \n",
      "69 \t100   \t0.802489\t0.0709171  \t0.844425   \t0.567989   \n",
      "70 \t100   \t0.773251\t0.073072   \t0.844425   \t0.61506    \n",
      "71 \t100   \t0.794277\t0.0715072  \t0.844425   \t0.580503   \n",
      "72 \t100   \t0.799541\t0.0659683  \t0.844425   \t0.580646   \n",
      "73 \t100   \t0.782456\t0.0780523  \t0.844425   \t0.591283   \n",
      "74 \t100   \t0.806575\t0.0663775  \t0.844425   \t0.6125     \n",
      "75 \t100   \t0.797866\t0.0734245  \t0.844425   \t0.567989   \n",
      "76 \t100   \t0.801276\t0.0689018  \t0.844425   \t0.580646   \n",
      "77 \t100   \t0.810024\t0.0566025  \t0.844425   \t0.700782   \n",
      "78 \t100   \t0.790107\t0.0832375  \t0.844425   \t0.564889   \n",
      "79 \t100   \t0.811249\t0.0529318  \t0.844425   \t0.698848   \n",
      "80 \t100   \t0.804988\t0.074812   \t0.844425   \t0.59572    \n",
      "Genetic Feature Selection: Index(['sofa_coagulation', 'sofa_cardiovascular', 'sofa_cns', 'sofa_renal',\n",
      "       'gender', 'charlson_comorbidity_index'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n#X = median_imputed_noncontin.drop('outcome',axis= 1)\\n#X = median_imputed_noncontin[['sofa_cns', 'charlson_comorbidity_index']]\\n#y = median_imputed_noncontin['outcome']\\nX = smoten_noncontin.drop('outcome',axis= 1)\\ny = smoten_noncontin['outcome']\\n\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\\n\\nlinear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\\nrbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\\npoly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\\nsig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\\n\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_linear = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('linear SVM')\\nprint(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_rbf = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('rbf SVM')\\nprint(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_poly = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('polynomial SVM')\\nprint(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_sig = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('sigmoid SVM')\\nprint(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "\n",
    "'''\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "ordEnc = OrdinalEncoder()\n",
    "encoded_gender = noncontinuous_select['gender'].to_numpy()\n",
    "encoded_gender = encoded_gender.reshape(-1, 1)\n",
    "encoded_gender = pd.DataFrame(ordEnc.fit_transform(encoded_gender), columns = ['gender']) #1 male, 0 female\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "def smotenThis(table, lst, y_var):    \n",
    "    X = table[lst]\n",
    "    y = table[y_var].to_numpy()\n",
    "    y = y.ravel()\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    oversample = SMOTEN()\n",
    "    X, y = oversample.fit_resample(X, y)    \n",
    "    array_X = pd.DataFrame(X)\n",
    "    array_y = pd.DataFrame(y, columns = [y_var])\n",
    "    \n",
    "    output = pd.concat([array_X, array_y], axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "smoten_noncontin = smotenThis(median_imputed_noncontin, ['sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index'] ,'outcome')\n",
    "smoten_noncontin.to_csv('smoten_noncontin.csv', index=False)  #comment to not write data\n",
    "'''\n",
    "\n",
    "#median_imputed_noncontin = pd.read_csv('median_imputed_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "#'''\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "geneticFeature = GAFeatureSelectionCV(estimator, generations=80) #80 generations is default\n",
    "geneticFeature.fit(X,y)\n",
    "print('Genetic Feature Selection:', X.columns[geneticFeature.support_])\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=3)\n",
    "#sfs = SequentialFeatureSelector(knn, n_features_to_select='auto')\n",
    "#sfs.fit(X, y)\n",
    "#print('Step Forward Selecition:', sfs.get_support())\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#X = median_imputed_noncontin[['sofa_cns', 'charlson_comorbidity_index']]\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('linear SVM')\n",
    "print(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rbf = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('rbf SVM')\n",
    "print(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_poly = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('polynomial SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_sig = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('sigmoid SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f407ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Forward Selecition: [ True False  True False False  True] ['sofa_coagulation' 'sofa_cns' 'charlson_comorbidity_index']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n#X = median_imputed_noncontin.drop('outcome',axis= 1)\\n#X = median_imputed_noncontin[['sofa_cns', 'charlson_comorbidity_index']]\\n#y = median_imputed_noncontin['outcome']\\nX = smoten_noncontin.drop('outcome',axis= 1)\\ny = smoten_noncontin['outcome']\\n\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\\n\\nlinear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\\nrbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\\npoly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\\nsig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\\n\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_linear = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('linear SVM')\\nprint(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_rbf = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('rbf SVM')\\nprint(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_poly = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('polynomial SVM')\\nprint(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\\n\\nclf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\\nclf.fit(X_train, y_train)\\ny_pred_sig = clf.predict(X_test)\\noutcome_labels = ['Intubation False', 'Intubation True']\\nprint('sigmoid SVM')\\nprint(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "\n",
    "'''\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "ordEnc = OrdinalEncoder()\n",
    "encoded_gender = noncontinuous_select['gender'].to_numpy()\n",
    "encoded_gender = encoded_gender.reshape(-1, 1)\n",
    "encoded_gender = pd.DataFrame(ordEnc.fit_transform(encoded_gender), columns = ['gender']) #1 male, 0 female\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "def smotenThis(table, lst, y_var):    \n",
    "    X = table[lst]\n",
    "    y = table[y_var].to_numpy()\n",
    "    y = y.ravel()\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    oversample = SMOTEN()\n",
    "    X, y = oversample.fit_resample(X, y)    \n",
    "    array_X = pd.DataFrame(X)\n",
    "    array_y = pd.DataFrame(y, columns = [y_var])\n",
    "    \n",
    "    output = pd.concat([array_X, array_y], axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "smoten_noncontin = smotenThis(median_imputed_noncontin, ['sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index'] ,'outcome')\n",
    "smoten_noncontin.to_csv('smoten_noncontin.csv', index=False)  #comment to not write data\n",
    "'''\n",
    "\n",
    "#median_imputed_noncontin = pd.read_csv('median_imputed_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "#'''\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "#estimator = DecisionTreeClassifier()\n",
    "#geneticFeature = GAFeatureSelectionCV(estimator, generations=80) #80 generations is default\n",
    "#geneticFeature.fit(X,y)\n",
    "#print('Genetic Feature Selection:', X.columns[geneticFeature.support_])\n",
    "\n",
    "knn = KNeighborsClassifier() #n_neighbors=5 default\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select='auto')\n",
    "sfs.fit(X, y)\n",
    "print('Step Forward Selecition:', sfs.get_support(), sfs.get_feature_names_out())\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#X = median_imputed_noncontin[['sofa_cns', 'charlson_comorbidity_index']]\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "X = smoten_noncontin.drop('outcome',axis= 1)\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('linear SVM')\n",
    "print(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rbf = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('rbf SVM')\n",
    "print(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_poly = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('polynomial SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_sig = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('sigmoid SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3918b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.65      0.82      0.72      6902\n",
      " Intubation True       0.77      0.57      0.65      7162\n",
      "\n",
      "        accuracy                           0.69     14064\n",
      "       macro avg       0.71      0.69      0.69     14064\n",
      "    weighted avg       0.71      0.69      0.69     14064\n",
      "\n",
      "rbf SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.66      0.80      0.73      6902\n",
      " Intubation True       0.76      0.61      0.68      7162\n",
      "\n",
      "        accuracy                           0.70     14064\n",
      "       macro avg       0.71      0.71      0.70     14064\n",
      "    weighted avg       0.71      0.70      0.70     14064\n",
      "\n",
      "polynomial SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.60      0.85      0.70      6902\n",
      " Intubation True       0.76      0.46      0.57      7162\n",
      "\n",
      "        accuracy                           0.65     14064\n",
      "       macro avg       0.68      0.65      0.64     14064\n",
      "    weighted avg       0.68      0.65      0.64     14064\n",
      "\n",
      "sigmoid SVM\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Intubation False       0.60      0.85      0.70      6902\n",
      " Intubation True       0.76      0.46      0.57      7162\n",
      "\n",
      "        accuracy                           0.65     14064\n",
      "       macro avg       0.68      0.65      0.64     14064\n",
      "    weighted avg       0.68      0.65      0.64     14064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN\n",
    "\n",
    "'''\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "noncontinuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "#print(noncontinuous_select)\n",
    "\n",
    "noncontinuous_var = ['gender','sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index', 'outcome']\n",
    "\n",
    "X = noncontinuous_select['sofa_coagulation'].to_numpy()\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "knn_imputer = KNNImputer()\n",
    "knn_imputed_var = pd.DataFrame(knn_imputer.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_knn_imputer(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "        \n",
    "        knn_imputer = KNNImputer()\n",
    "        knn_imputed_temp = pd.DataFrame(knn_imputer.fit_transform(X), columns = [i])\n",
    "        concat_to_list = pd.concat([concat_to_list, knn_imputed_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "knn_imputed_var = more_knn_imputer(noncontinuous_var[2:-2], knn_imputed_var)\n",
    "knn_imputed_var.to_csv('knn_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "ordEnc = OrdinalEncoder()\n",
    "encoded_gender = noncontinuous_select['gender'].to_numpy()\n",
    "encoded_gender = encoded_gender.reshape(-1, 1)\n",
    "encoded_gender = pd.DataFrame(ordEnc.fit_transform(encoded_gender), columns = ['gender']) #1 male, 0 female\n",
    "\n",
    "knn_imputed_noncontin = pd.concat([knn_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "knn_imputed_noncontin.to_csv('knn_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "imp_median = SimpleImputer(strategy='median')\n",
    "imp_median_var = pd.DataFrame(imp_median.fit_transform(X), columns = ['sofa_coagulation'])  \n",
    "\n",
    "def more_imp_median(lst, concat_to_list):\n",
    "    for i in lst:\n",
    "        X = lambda i: noncontinuous_select[i].to_numpy()\n",
    "        X = X(i).reshape(-1, 1)\n",
    "\n",
    "        imp_median = SimpleImputer(strategy='median')\n",
    "        imp_median_temp = pd.DataFrame(imp_median.fit_transform(X), columns = [i])  \n",
    "        concat_to_list = pd.concat([concat_to_list, imp_median_temp], axis=1)\n",
    "    return concat_to_list\n",
    "\n",
    "median_imputed_var = more_imp_median(noncontinuous_var[2:-2], imp_median_var)\n",
    "median_imputed_var.to_csv('median_imputed_noncontin_var.csv', index=False)  #comment to not write data\n",
    "\n",
    "median_imputed_noncontin = pd.concat([median_imputed_var, encoded_gender, noncontinuous_select[['charlson_comorbidity_index', 'outcome']]], axis=1)\n",
    "median_imputed_noncontin.to_csv('median_imputed_noncontin.csv', index=False)  #comment to not write data\n",
    "\n",
    "def smotenThis(table, lst, y_var):    \n",
    "    X = table[lst]\n",
    "    y = table[y_var].to_numpy()\n",
    "    y = y.ravel()\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    oversample = SMOTEN()\n",
    "    X, y = oversample.fit_resample(X, y)    \n",
    "    array_X = pd.DataFrame(X)\n",
    "    array_y = pd.DataFrame(y, columns = [y_var])\n",
    "    \n",
    "    output = pd.concat([array_X, array_y], axis=1)\n",
    "    \n",
    "    return output\n",
    "\n",
    "smoten_noncontin = smotenThis(median_imputed_noncontin, ['sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index'] ,'outcome')\n",
    "smoten_noncontin.to_csv('smoten_noncontin.csv', index=False)  #comment to not write data\n",
    "'''\n",
    "\n",
    "#median_imputed_noncontin = pd.read_csv('median_imputed_noncontin.csv', index_col=False)\n",
    "smoten_noncontin = pd.read_csv('smoten_noncontin.csv', index_col=False)\n",
    "\n",
    "'''\n",
    "X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "y = median_imputed_noncontin['outcome']\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "geneticFeature = GAFeatureSelectionCV(estimator, generations=10) #80 generations is default\n",
    "geneticFeature.fit(X,y)\n",
    "print('Genetic Feature Selection:', X.columns[geneticFeature.support_])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n",
    "sfs.fit(X, y)\n",
    "print('Step Forward Selecition:', sfs.get_support())\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "#X = median_imputed_noncontin.drop('outcome',axis= 1)\n",
    "#X = median_imputed_noncontin[['sofa_coagulation', 'sofa_cardiovascular', 'sofa_cns', 'sofa_renal', 'gender', 'charlson_comorbidity_index']]\n",
    "#y = median_imputed_noncontin['outcome']\n",
    "X = smoten_noncontin[['sofa_coagulation', 'sofa_cns', 'charlson_comorbidity_index']]\n",
    "y = smoten_noncontin['outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 0) #train split\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=2, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='linear', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('linear SVM')\n",
    "print(classification_report(y_test, y_pred_linear, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rbf = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('rbf SVM')\n",
    "print(classification_report(y_test, y_pred_rbf, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='poly', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_poly = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('polynomial SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), svm.SVC(kernel='sigmoid', C=1.0))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_sig = clf.predict(X_test)\n",
    "outcome_labels = ['Intubation False', 'Intubation True']\n",
    "print('sigmoid SVM')\n",
    "print(classification_report(y_test, y_pred_poly, target_names=outcome_labels))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598a4d9",
   "metadata": {},
   "source": [
    "continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e62d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "data_missing_less_40p = pd.read_csv('Assignment_1_data_missing_less_40p.csv', index_col=False)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "noncontinuous_var = ['gender', 'sofa_coagulation', 'sofa_cardiovascular','sofa_cns', 'sofa_renal', 'charlson_comorbidity_index']\n",
    "\n",
    "data_continuous = data_missing_less_40p.loc[:, ~data_missing_less_40p.columns.isin(noncontinuous_var)]\n",
    "\n",
    "\n",
    "data_continuous.to_csv('continuous_select.csv', index=False)  #comment to not write data\n",
    "\n",
    "continuous_select = pd.read_csv('noncontinuous_select.csv', index_col=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
